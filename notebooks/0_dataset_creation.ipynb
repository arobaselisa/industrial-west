{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b305bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import os\n",
    "import subprocess\n",
    "import  tarfile\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import ast\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937562de",
   "metadata": {},
   "source": [
    "### The New York Herald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acbf297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the dataset (might take a few minutes) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Institution (2)/United States/dlc_ambrosia_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_bindweed_ver02.tar.bz2\n",
      "x Institution (2)/United States/dlc_crowfoot_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_deadnettle_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_eucalyptus_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_fairymoss_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_goldenglow_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_houseleek_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_itchweed_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_juneberry_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_kudzu_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_laceflower_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_marcus_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_nosebleed_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_poppy_ver01.tar.bz2\n",
      "x Institution (2)/United States/dlc_quercitron_ver01.tar.bz2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of articles talking about steel  0.0\n"
     ]
    }
   ],
   "source": [
    "# Find all tar.bz2 files in global tar file\n",
    "tar = tarfile.open(\"../data/Institution.tar\")\n",
    "bz2_paths = [name for name in tar.getnames() if \"Institution (2)/United States/\" in name]\n",
    "\n",
    "# Create dataframes\n",
    "coal_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "steel_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "telegraph_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "elec_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "dates_us = set()\n",
    "total_articles_count = 0\n",
    "\n",
    "print(\"Creating the dataset (might take a few minutes) ...\")\n",
    "\n",
    "# open different US tar files one by one\n",
    "for p in bz2_paths[1:]: # exclude first odt file\n",
    "    subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", p], stdout=subprocess.PIPE, text=True)\n",
    "    tar = tarfile.open(p)\n",
    "    for m in tar:\n",
    "        if \".txt\" in m.name:\n",
    "            total_articles_count += 1\n",
    "            pub_date = m.name.split(\"/\")[1] + \"-\" + m.name.split(\"/\")[2] + \"-\" + m.name.split(\"/\")[3] \n",
    "            dates_us.add(pub_date)\n",
    "            f=tar.extractfile(m)\n",
    "            content=f.read()\n",
    "            if b'coal' in content:\n",
    "                coal_articles.loc[m.name.replace(\"/ocr.txt\", \"\")] = {\"publication_date\" : pub_date, \"content\":content.decode(\"utf-8\")}\n",
    "            if b'steel' in content:\n",
    "                steel_articles.loc[m.name.replace(\"/ocr.txt\", \"\")] = {\"publication_date\" : pub_date, \"content\":content.decode(\"utf-8\")}\n",
    "            if b'telegraph' in content:\n",
    "                telegraph_articles.loc[m.name.replace(\"/ocr.txt\", \"\")] = {\"publication_date\" : pub_date, \"content\":content.decode(\"utf-8\")}\n",
    "            if b'electricity' in content:\n",
    "                elec_articles.loc[m.name.replace(\"/ocr.txt\", \"\")] = {\"publication_date\" : pub_date, \"content\":content.decode(\"utf-8\")}\n",
    "\n",
    "    # Removes files to save memory\n",
    "    subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])\n",
    "    # Intermediate saves\n",
    "    coal_articles.to_csv(\"../data/coal_articles_us.csv\")\n",
    "    steel_articles.to_csv(\"../data/steel_articles_us.csv\")\n",
    "    telegraph_articles.to_csv(\"../data/telegraph_articles_us.csv\")\n",
    "    elec_articles.to_csv(\"../data/elec_articles_us.csv\")\n",
    "    \n",
    "    # Save dates\n",
    "    with open('../data/dates_us.txt','w') as f:\n",
    "        f.write(str(dates_us)) \n",
    "\n",
    "print(\"Proportion of articles talking about coal\", len(coal_articles.index)/total_articles_count)\n",
    "print(\"Proportion of articles talking about steel\", len(steel_articles.index)/total_articles_count)\n",
    "print(\"Proportion of articles talking about telegraph\", len(telegraph_articles.index)/total_articles_count)\n",
    "print(\"Proportion of articles talking about electricity\", len(elec_articles.index)/total_articles_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d200fcd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues in the american dataset :  14492\n",
      "Total number of issues with the word 'coal' :  12000\n",
      "Total number of issues with the word 'telegraph' :  12397\n",
      "Total number of issues with the word 'steel' :  7798\n",
      "Total number of issues with the word 'electricity' :  2593\n"
     ]
    }
   ],
   "source": [
    "# Only keep dates that are in the time period studied\n",
    "with open('../data/dates_us.txt','r') as f:\n",
    "    dates_us = ast.literal_eval(f.read())\n",
    "dates_us = {d for d in dates_us if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930}\n",
    "\n",
    "cdfus = pd.read_csv(\"../data/coal_articles_us.csv\")\n",
    "all_us_coal_dates = set(cdfus.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_us_coal_dates = len({d for d in all_us_coal_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "tdfus = pd.read_csv(\"../data/telegraph_articles_us.csv\")\n",
    "all_us_telegraph_dates = set(tdfus.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_us_telegraph_dates = len({d for d in all_us_telegraph_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "sdfus = pd.read_csv(\"../data/steel_articles_us.csv\")\n",
    "all_us_steel_dates = set(sdfus.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_us_steel_dates = len({d for d in all_us_steel_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "edfus = pd.read_csv(\"../data/elec_articles_us.csv\")\n",
    "all_us_elec_dates = set(edfus.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_us_elec_dates = len({d for d in all_us_elec_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "\n",
    "print(\"Total number of issues in the american dataset : \", len(dates_us))\n",
    "print(\"Total number of issues with the word 'coal' : \", n_all_us_coal_dates)\n",
    "print(\"Total number of issues with the word 'telegraph' : \", n_all_us_telegraph_dates)\n",
    "print(\"Total number of issues with the word 'steel' : \", n_all_us_steel_dates)\n",
    "print(\"Total number of issues with the word 'electricity' : \", n_all_us_elec_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491deca2",
   "metadata": {},
   "source": [
    "### Le Figaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47aa939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open French archive\n",
    "subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", \"Institution (2)/France/le_figaro.zip\"], stdout=subprocess.PIPE, text=True)\n",
    "# Unzip \n",
    "with zipfile.ZipFile('./Institution (2)/France/le_figaro.zip') as zip_ref:\n",
    "    zip_ref.extractall('./Institution (2)/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cc4ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28502/28502 [00:00<00:00, 239273.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get list of all articles\n",
    "every_article = glob.glob('./Institution (2)/*/*/*.json')\n",
    "coal_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "telegraph_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "steel_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "elec_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "dates_fr = set()\n",
    "for article in tqdm(every_article):\n",
    "    date = article.split(\"/\")[3][:4] + \"-\" + article.split(\"/\")[3][4:6] + \"-\" + article.split(\"/\")[3][6:]\n",
    "    dates_fr.add(date)\n",
    "    with open(article, 'r') as f:\n",
    "        data = json.load(f)   \n",
    "        if \"charbon\" in unidecode.unidecode(str.lower(data[\"contentAsText\"][0])):\n",
    "            coal_articles.loc[\"figaro_\" + article.split(\"/\")[3]] = {\"publication_date\" : article.split(\"/\")[3], \"content\":data[\"contentAsText\"][0]}\n",
    "        if \"telegraphe\" in unidecode.unidecode(str.lower(data[\"contentAsText\"][0])):\n",
    "            telegraph_articles.loc[\"figaro_\" + article.split(\"/\")[3]] = {\"publication_date\" : article.split(\"/\")[3], \"content\":data[\"contentAsText\"][0]}\n",
    "        if \" acier\" in unidecode.unidecode(str.lower(data[\"contentAsText\"][0])):\n",
    "            steel_articles.loc[\"figaro_\" + article.split(\"/\")[3]] = {\"publication_date\" : article.split(\"/\")[3], \"content\":data[\"contentAsText\"][0]}\n",
    "        if \"electricite\" in unidecode.unidecode(str.lower(data[\"contentAsText\"][0])):\n",
    "            elec_articles.loc[\"figaro_\" + article.split(\"/\")[3]] = {\"publication_date\" : article.split(\"/\")[3], \"content\":data[\"contentAsText\"][0]}\n",
    "        \n",
    "# Save data\n",
    "coal_articles.to_csv(\"../data/coal_articles_fr.csv\")\n",
    "telegraph_articles.to_csv(\"../data/telegraph_articles_fr.csv\")\n",
    "steel_articles.to_csv(\"../data/steel_articles_fr.csv\")\n",
    "elec_articles.to_csv(\"../data/elec_articles_fr.csv\")\n",
    "\n",
    "# Save dates\n",
    "with open('../data/dates_fr.txt','w') as f:\n",
    "    f.write(str(dates_fr))\n",
    "\n",
    "# Removes files to save memory\n",
    "subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5a08a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues in the american dataset :  19917\n",
      "Total number of issues with the word 'coal' :  1955\n",
      "Total number of issues with the word 'telegraph' :  4889\n",
      "Total number of issues with the word 'steel' :  352\n",
      "Total number of issues with the word 'electricity' :  1058\n"
     ]
    }
   ],
   "source": [
    "# Only keep dates that are in the time period studied\n",
    "with open('../data/dates_fr.txt','r') as f:\n",
    "    dates_fr = ast.literal_eval(f.read())\n",
    "dates_fr = {d for d in dates_fr if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930}\n",
    "\n",
    "cdffr = pd.read_csv(\"../data/coal_articles_fr.csv\")\n",
    "all_fr_coal_dates = set(cdffr.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_fr_coal_dates = len({d for d in all_fr_coal_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "tdffr = pd.read_csv(\"../data/telegraph_articles_fr.csv\")\n",
    "all_fr_telegraph_dates = set(tdffr.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_fr_telegraph_dates = len({d for d in all_fr_telegraph_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "sdffr = pd.read_csv(\"../data/steel_articles_fr.csv\")\n",
    "all_fr_steel_dates = set(sdffr.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_fr_steel_dates = len({d for d in all_fr_steel_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "edffr = pd.read_csv(\"../data/elec_articles_fr.csv\")\n",
    "all_fr_elec_dates = set(edffr.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_fr_elec_dates = len({d for d in all_fr_elec_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "\n",
    "print(\"Total number of issues in the frenc dataset : \", len(dates_fr))\n",
    "print(\"Total number of issues with the word 'coal' : \", n_all_fr_coal_dates)\n",
    "print(\"Total number of issues with the word 'telegraph' : \", n_all_fr_telegraph_dates)\n",
    "print(\"Total number of issues with the word 'steel' : \", n_all_fr_steel_dates)\n",
    "print(\"Total number of issues with the word 'electricity' : \", n_all_fr_elec_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe5da4",
   "metadata": {},
   "source": [
    "### El Imparcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51015552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Institution (2)/Spain/2171-0244-el-imparcial-madrid-1867.zip\n"
     ]
    }
   ],
   "source": [
    "# Open spanish archive\n",
    "subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", \"Institution (2)/Spain/2171-0244-el-imparcial-madrid-1867.zip\"], stdout=subprocess.PIPE, text=True)\n",
    "# Unzip \n",
    "with zipfile.ZipFile('./Institution (2)/Spain/2171-0244-el-imparcial-madrid-1867.zip') as zip_ref:\n",
    "    zip_ref.extractall('./Institution (2)/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "569dd11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 23008/23008 [00:00<00:00, 269860.20it/s]\n"
     ]
    }
   ],
   "source": [
    "every_article = glob.glob('./Institution (2)/*.txt')\n",
    "coal_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "steel_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "telegraph_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "elec_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "dates_es = set()\n",
    "\n",
    "for article in tqdm(every_article):\n",
    "    date = article.split(\"/\")[2].split(\"_\")[0][:4] + \"-\" + article.split(\"/\")[2].split(\"_\")[0][4:6] + \"-\" + article.split(\"/\")[2].split(\"_\")[0][6:8]\n",
    "    dates_es.add(date)\n",
    "    with open(article, 'r') as f:\n",
    "        data = \"\\n\".join(f.readlines())\n",
    "        if \"carbon\" in unidecode.unidecode(str.lower(data)):\n",
    "            coal_articles.loc[\"imparcial_\" + article.split(\"/\")[2].split(\"_\")[0]] = {\"publication_date\" : date, \"content\":data}\n",
    "        if \"acero\" in unidecode.unidecode(str.lower(data)):\n",
    "            steel_articles.loc[\"imparcial_\" + article.split(\"/\")[2].split(\"_\")[0]] = {\"publication_date\" : date, \"content\":data}\n",
    "        if \"telegrafo\" in unidecode.unidecode(str.lower(data)):\n",
    "            telegraph_articles.loc[\"imparcial_\" + article.split(\"/\")[2].split(\"_\")[0]] = {\"publication_date\" : date, \"content\":data}\n",
    "        if \"electricidad\" in unidecode.unidecode(str.lower(data)):\n",
    "            elec_articles.loc[\"imparcial_\" + article.split(\"/\")[2].split(\"_\")[0]] = {\"publication_date\" : date, \"content\":data}\n",
    "\n",
    "# Save data\n",
    "coal_articles.to_csv(\"../data/coal_articles_es.csv\")\n",
    "telegraph_articles.to_csv(\"../data/telegraph_articles_es.csv\")\n",
    "steel_articles.to_csv(\"../data/steel_articles_es.csv\")\n",
    "elec_articles.to_csv(\"../data/elec_articles_es.csv\")\n",
    "\n",
    "# Save dates\n",
    "with open('../data/dates_es.txt','w') as f:\n",
    "    f.write(str(dates_es))\n",
    "\n",
    "# Removes files to save memory\n",
    "subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec9644f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues in the spanish dataset :  22062\n",
      "Total number of issues with the word 'coal' :  14031\n",
      "Total number of issues with the word 'telegraph' :  15102\n",
      "Total number of issues with the word 'steel' :  11442\n",
      "Total number of issues with the word 'electricity' :  4678\n"
     ]
    }
   ],
   "source": [
    "# Only keep dates that are in the time period studied\n",
    "with open('../data/dates_es.txt','r') as f:\n",
    "    dates_es = ast.literal_eval(f.read())\n",
    "dates_es = {d for d in dates_es if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930}\n",
    "\n",
    "cdfes = pd.read_csv(\"../data/coal_articles_es.csv\")\n",
    "all_es_coal_dates = set(cdfes.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_es_coal_dates = len({d for d in all_es_coal_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "tdfes = pd.read_csv(\"../data/telegraph_articles_es.csv\")\n",
    "all_es_telegraph_dates = set(tdfes.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_es_telegraph_dates = len({d for d in all_es_telegraph_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "sdfes = pd.read_csv(\"../data/steel_articles_es.csv\")\n",
    "all_es_steel_dates = set(sdfes.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_es_steel_dates = len({d for d in all_es_steel_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "edfes = pd.read_csv(\"../data/elec_articles_es.csv\")\n",
    "all_es_elec_dates = set(edfes.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_es_elec_dates = len({d for d in all_es_elec_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "\n",
    "print(\"Total number of issues in the spanish dataset : \", len(dates_es))\n",
    "print(\"Total number of issues with the word 'coal' : \", n_all_es_coal_dates)\n",
    "print(\"Total number of issues with the word 'telegraph' : \", n_all_es_telegraph_dates)\n",
    "print(\"Total number of issues with the word 'steel' : \", n_all_es_steel_dates)\n",
    "print(\"Total number of issues with the word 'electricity' : \", n_all_es_elec_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9934c",
   "metadata": {},
   "source": [
    "### Neue Hamburger Zeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_text(file_name):\n",
    "    tree = ET.parse(file_name) \n",
    "    root = tree.getroot()\n",
    "    txt = \"\"\n",
    "    for textblock in root.findall(\".//{http://www.loc.gov/standards/alto/ns-v2#}TextBlock\"):\n",
    "        txt += \" \".join([s.attrib[\"CONTENT\"] for s in textblock.findall('.//{http://www.loc.gov/standards/alto/ns-v2#}String')])\n",
    "        txt += \"\\n\\n\"\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80da3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "coal_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "elec_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "telegraph_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "steel_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "dates_de = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f55481f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Institution (2)/Hamburg/PPN689063377.zip\n",
      "100%|███████████████████████████████| 152554/152554 [00:00<00:00, 367455.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['rm', '-rf', 'Institution (2)'], returncode=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open spanish archive\n",
    "subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", \"Institution (2)/Hamburg/PPN689063377.zip\"], stdout=subprocess.PIPE, text=True)\n",
    "# Unzip \n",
    "with zipfile.ZipFile('./Institution (2)/Hamburg/PPN689063377.zip') as zip_ref:\n",
    "    zip_ref.extractall('./Institution (2)/')\n",
    "\n",
    "all_files = sorted(glob.glob(\"./Institution (2)/*/*.xml\"))\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    pub_date = file.split(\"_\")[2][:4] + \"-\" + file.split(\"_\")[2][4:6] + \"-\" + file.split(\"_\")[2][6:8]\n",
    "    dates_de.add(pub_date)\n",
    "\"\"\"\n",
    " text = get_whole_text(file)\n",
    "    for block in text.split(\"\\n\"):\n",
    "        if \"Kohle\" in block:\n",
    "            try :\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": coal_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Elektrizität\" in block:\n",
    "            try :\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": elec_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Stahl\" in block:\n",
    "            try :\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": steel_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Telegraph\" in block:\n",
    "            try :\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": telegraph_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\"\"\"\n",
    "\n",
    "# Removes files to save memory\n",
    "subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be0f3f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Institution (2)/Hamburg/PPN689063512.zip\n",
      "100%|███████████████████████████████| 104194/104194 [00:00<00:00, 388215.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['rm', '-rf', 'Institution (2)'], returncode=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", \"Institution (2)/Hamburg/PPN689063512.zip\"], stdout=subprocess.PIPE, text=True)\n",
    "#Unzip \n",
    "with zipfile.ZipFile('./Institution (2)/Hamburg/PPN689063512.zip') as zip_ref:\n",
    "    zip_ref.extractall('./Institution (2)/')\n",
    "\n",
    "all_files = sorted(glob.glob(\"./Institution (2)/*/*.xml\"))\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    pub_date = file.split(\"_\")[2][:4] + \"-\" + file.split(\"_\")[2][4:6] + \"-\" + file.split(\"_\")[2][6:8]\n",
    "    dates_de.add(pub_date)\n",
    "\"\"\"\n",
    " text = get_whole_text(file)\n",
    "    for block in text.split(\"\\n\"):\n",
    "        if \"Kohle\" in block:\n",
    "            try :\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": coal_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Elektrizität\" in block:\n",
    "            try :\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": elec_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Stahl\" in block:\n",
    "            try :\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": steel_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Telegraph\" in block:\n",
    "            try :\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": telegraph_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\"\"\"\n",
    "\n",
    "# Removes files to save memory\n",
    "subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "010fa17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x Institution (2)/Hamburg/PPN689065744 (1).zip\n",
      "100%|███████████████████████████████| 122923/122923 [00:00<00:00, 309911.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['rm', '-rf', 'Institution (2)'], returncode=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open spanish archive\n",
    "subprocess.run([\"tar\", \"-xvf\", \"../data/Institution.tar\", \"Institution (2)/Hamburg/PPN689065744 (1).zip\"], stdout=subprocess.PIPE, text=True)\n",
    "# Unzip \n",
    "with zipfile.ZipFile('./Institution (2)/Hamburg/PPN689065744 (1).zip') as zip_ref:\n",
    "    zip_ref.extractall('./Institution (2)/')\n",
    "\n",
    "all_files = sorted(glob.glob(\"./Institution (2)/*/*.xml\"))\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    pub_date = file.split(\"_\")[2][:4] + \"-\" + file.split(\"_\")[2][4:6] + \"-\" + file.split(\"_\")[2][6:8]\n",
    "    dates_de.add(pub_date)\n",
    "\"\"\"\n",
    " text = get_whole_text(file)\n",
    "    for block in text.split(\"\\n\"):\n",
    "        if \"Kohle\" in block:\n",
    "            try :\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": coal_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                coal_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Elektrizität\" in block:\n",
    "            try :\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": elec_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                elec_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Stahl\" in block:\n",
    "            try :\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": steel_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                steel_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\n",
    "        if \"Telegraph\" in block:\n",
    "            try :\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": telegraph_articles.loc[\"hamburg_\" + pub_date].content + block}\n",
    "            except:\n",
    "                telegraph_articles.loc[\"hamburg_\" + pub_date] = {\"publication_date\" : pub_date, \"content\": block}\"\"\"\n",
    "\n",
    "# Removes files to save memory\n",
    "subprocess.run([\"rm\", \"-rf\", \"Institution (2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "coal_articles.to_csv(\"../data/coal_articles_es.csv\")\n",
    "telegraph_articles.to_csv(\"../data/telegraph_articles_es.csv\")\n",
    "steel_articles.to_csv(\"../data/steel_articles_es.csv\")\n",
    "elec_articles.to_csv(\"../data/elec_articles_es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb47b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dates\n",
    "with open('../data/dates_de.txt','w') as f:\n",
    "    f.write(str(dates_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb4e022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues in the german dataset :  13836\n",
      "Total number of issues with the word 'coal' :  12635\n",
      "Total number of issues with the word 'telegraph' :  10372\n",
      "Total number of issues with the word 'steel' :  10358\n",
      "Total number of issues with the word 'electricity' :  6189\n"
     ]
    }
   ],
   "source": [
    "# Only keep dates that are in the time period studied\n",
    "with open('../data/dates_de.txt','r') as f:\n",
    "    dates_de = ast.literal_eval(f.read())\n",
    "dates_de = {d for d in dates_de if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930}\n",
    "\n",
    "cdfde = pd.read_csv(\"../data/coal_articles_de.csv\")\n",
    "all_de_coal_dates = set(cdfde.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_de_coal_dates = len({d for d in all_de_coal_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "tdfde = pd.read_csv(\"../data/telegraph_articles_de.csv\")\n",
    "all_de_telegraph_dates = set(tdfde.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_de_telegraph_dates = len({d for d in all_de_telegraph_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "sdfde = pd.read_csv(\"../data/steel_articles_de.csv\")\n",
    "all_de_steel_dates = set(sdfde.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_de_steel_dates = len({d for d in all_de_steel_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "edfde = pd.read_csv(\"../data/elec_articles_de.csv\")\n",
    "all_de_elec_dates = set(edfde.groupby(\"publication_date\").count().index.to_list())\n",
    "n_all_de_elec_dates = len({d for d in all_de_elec_dates if int(d.split('-')[0]) > 1840 and int(d.split('-')[0]) < 1930})\n",
    "\n",
    "\n",
    "print(\"Total number of issues in the german dataset : \", len(dates_de))\n",
    "print(\"Total number of issues with the word 'coal' : \", n_all_de_coal_dates)\n",
    "print(\"Total number of issues with the word 'telegraph' : \", n_all_de_telegraph_dates)\n",
    "print(\"Total number of issues with the word 'steel' : \", n_all_de_steel_dates)\n",
    "print(\"Total number of issues with the word 'electricity' : \", n_all_de_elec_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6a7aa",
   "metadata": {},
   "source": [
    "### La Stampa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5945b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(\"../data/Italian newspaper/out_fernandez/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kw_lines(lines, kw):\n",
    "    sentences = lines.split(\".\")\n",
    "    coal_idx = [idx for idx in range(len(sentences)) if kw in sentences[idx]]\n",
    "    coal_idx_aug = set(sum(list(map(lambda x: [max(0, x-1), x, min(x+1, len(sentences)-1)], coal_idx)), []))\n",
    "    return \" \".join([sentences[i] for i in coal_idx_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4b6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 133/133 [00:08<00:00, 15.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                content = get_kw_lines(l, \"carbone\")\\n                if content != \"\":\\n                    coal_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\\n                content = get_kw_lines(l, \"acciaio\")\\n                if content != \"\":\\n                    steel_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\\n                content = get_kw_lines(l, \"elettricità\")\\n                if content != \"\":\\n                    elec_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\\n                content = get_kw_lines(l, \"telegrafo\")\\n                if content != \"\":\\n                    telegraph_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\\n            \\ncoal_articles.to_csv(\"../data/coal_articles_it.csv\")\\nsteel_articles.to_csv(\"../data/steel_articles_it.csv\")\\ntelegraph_articles.to_csv(\"../data/telegraph_articles_it.csv\")\\nelec_articles.to_csv(\"../data/elec_articles_it.csv\")'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coal_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "steel_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "telegraph_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "elec_articles = pd.DataFrame(columns=[\"publication_date\", \"content\"])\n",
    "\n",
    "n_articles = 0\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            year = file.split(\"_\")[-1]\n",
    "            for i, l in enumerate(lines):\n",
    "                n_articles += 1\n",
    "                content = get_kw_lines(l, \"carbone\")\n",
    "                if content != \"\":\n",
    "                    coal_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\n",
    "                content = get_kw_lines(l, \"acciaio\")\n",
    "                if content != \"\":\n",
    "                    steel_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\n",
    "                content = get_kw_lines(l, \"elettricità\")\n",
    "                if content != \"\":\n",
    "                    elec_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\n",
    "                content = get_kw_lines(l, \"telegrafo\")\n",
    "                if content != \"\":\n",
    "                    telegraph_articles.loc[\"stampa_\" + str(year) + \"_\" + str(i)] = {\"publication_date\" : year, \"content\": content}\n",
    "            \n",
    "coal_articles.to_csv(\"../data/coal_articles_it.csv\")\n",
    "steel_articles.to_csv(\"../data/steel_articles_it.csv\")\n",
    "telegraph_articles.to_csv(\"../data/telegraph_articles_it.csv\")\n",
    "elec_articles.to_csv(\"../data/elec_articles_it.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "29d28496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles in the italian dataset :  54797\n",
      "Total number of articles with the word 'coal' :  2875\n",
      "Total number of articles with the word 'telegraph' :  4425\n",
      "Total number of articles with the word 'steel' :  39251\n",
      "Total number of articles with the word 'electricity' :  11951\n"
     ]
    }
   ],
   "source": [
    "cdfit = pd.read_csv(\"../data/coal_articles_it.csv\")\n",
    "n_all_it_coal_dates = len(cdfit.index.to_list())\n",
    "\n",
    "tdfit = pd.read_csv(\"../data/telegraph_articles_it.csv\")\n",
    "n_all_it_telegraph_dates = len(tdfit.index.to_list())\n",
    "\n",
    "sdfit = pd.read_csv(\"../data/steel_articles_it.csv\")\n",
    "n_all_it_steel_dates = len(sdfit.index.to_list())\n",
    "\n",
    "edfit = pd.read_csv(\"../data/elec_articles_it.csv\")\n",
    "n_all_it_elec_dates = len(edfit.index.to_list())\n",
    "\n",
    "\n",
    "print(\"Total number of articles in the italian dataset : \", n_articles)\n",
    "print(\"Total number of articles with the word 'coal' : \", n_all_it_coal_dates)\n",
    "print(\"Total number of articles with the word 'telegraph' : \", n_all_it_telegraph_dates)\n",
    "print(\"Total number of articles with the word 'steel' : \", n_all_it_steel_dates)\n",
    "print(\"Total number of articles with the word 'electricity' : \", n_all_it_elec_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
